ClubCpG cell-type deconvolution analysis
================

ClubCpG is a computational tool extracting heterogeneous signals in WGBS
read-level.

# **Data preparation**

ClubCpG toolkit provides *clubcpg-coverage* to define bins with given
size and detect reads fully covering al bings. This produces a .csv file
of bins for each chromosome.

``` bash
input_bam="bulk_1.bam" # Bam file to analyse
out_dir="/home/results/" # Directory to save the results

# Extract chromosomes in the given bam file
chr_list=$(samtools idxstats $input_bam | cut -f 1)

for i in $chr_list
do
    if [[ "$i" != *"chr"* ]]; then
        continue
    fi
    clubcpg-coverage -a $input_bam -n 10 -o $out_dir -chr $i --bin_size 100
done
```

You can filter out result csv files with respect to reads and CpGs
number thresholds. This step is highly recommended as WGBS data quality
depends on coverage. Although read-coverage \>= 10 and CpG-coverage \>=2
were recommended by the authors, we set up read-coverage \>= 20 and
CpG-coverage \>= 4 which generated better
performances.

``` bash
csv_files=$out_dir"/CompleteBins.*.csv" # List of result files generated by clubcpg-coverage
res_file=$out_dir"/FilteredBins.bulk_1.csv" # New file to save filtred bins

# Appends the filtered out results into one file
for f in $csv_files
do
    if [[ ! $f =~ "chr"[A-Z] ]];
    then
        cat $f | awk -F "," '$2>=20 && $3>=4' >> $res_file
    fi
done
```

# **ClubCpG clustering**

After filtering, you can run *clubcpg-cluster* to cluster bins. This
step will cluster bins based on bin\_id (chromosome and position) and
methylation
pattern.

``` bash
clubcpg-cluster -a $input_bam --bins $res_file -o $out_dir --bin_size 100 -m 4 -r 20 -n 10
```

Detailed usage is described in
<a href="url">https://clubcpg.readthedocs.io/en/latest/usage.html\#perform-clustering</a>

# **Cell-type deconvolution analysis**

Scott et al.Â proposed to use the bin clusters from ClubCpG for cell-type
proportion estimation in cell mixture samples. We implemented the
suggested pipelines in R code as below.

Firstly, we read in csv files for 20 pseudo-bulk samples and found
common clusters over all samples.

``` r
head(df_test[,1:3])
```

``` 
   chr1_101360300_0.0.0.0 chr1_109968500_0.0.0.0 chr1_111052500_1.1.1.1
```

bulk\_1 23 27 15 bulk\_2 24 26 25 bulk\_3 20 25 17 bulk\_4 23 29 18
bulk\_5 20 26 22 bulk\_6 22 24 21

``` r
dim(df_test)
```

\[1\] 20 1843

``` r
head(test_gt)
```

``` 
   Bcell_noncancer diffuse_large_B_cell_lymphoma
```

bulk\_1 0.1513154 0.8486846 bulk\_2 0.9452309 0.0547691 bulk\_3
0.1519955 0.8480045 bulk\_4 0.1898754 0.8101246 bulk\_5 0.6798783
0.3201217 bulk\_6 0.8014090 0.1985910 Since the suggested pipeline is
reference-based, we generated 100 reference samples with same cell types
and processed in same ways as how we processed pseudo-bulk samples.

``` r
head(df_train[,1:3])
```

    ##        chr1_143283300_1.1.1.1.1.1.1.1.1.1.1
    ## bulk_1                                   16
    ## bulk_2                                   17
    ## bulk_3                                   12
    ## bulk_4                                    8
    ## bulk_5                                   14
    ## bulk_6                                    9
    ##        chr1_156186400_1.1.1.1.1.1.1.1.1.1.1.1.1.1
    ## bulk_1                                         28
    ## bulk_2                                         25
    ## bulk_3                                         21
    ## bulk_4                                         25
    ## bulk_5                                         21
    ## bulk_6                                         18
    ##        chr1_156186500_1.1.1.1.1.1.1.1.1.1.1.1.1.1.1
    ## bulk_1                                           14
    ## bulk_2                                           15
    ## bulk_3                                           18
    ## bulk_4                                           16
    ## bulk_5                                           18
    ## bulk_6                                           19

``` r
dim(df_train)
```

    ## [1] 100 294

``` r
head(df_gt)
```

    ##          Bcell_noncancer diffuse_large_B_cell_lymphoma
    ## bulk_1         0.6535395                     0.3464605
    ## bulk_10        0.1285678                     0.8714322
    ## bulk_100       0.1700537                     0.8299463
    ## bulk_11        0.1599901                     0.8400099
    ## bulk_12        0.3769564                     0.6230436
    ## bulk_13        0.5412960                     0.4587040

Then, we conducted PCA dimensionality reduction on the reference data
and created multivariate linear regression model with top 20 PCs for
ground-truth cell-type proportions.

``` r
library(caret, quietly = T)
pc_train = prcomp(as.data.frame(df_train), scale. = T)
df_pc_train = as.data.frame(pc_train$x)

ctype = "Bcell_noncancer"
df_pc_train$gt = df_gt[rownames(df_pc_train), ctype]
train.control <- trainControl(method = "cv", number = 5)
model <- train(gt ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12 + PC13 + PC14 + PC15 + PC16 + PC17 + PC18 + PC19 + PC20, 
                   data = df_pc_train, method = "lm",
                   trControl = train.control)
```

The trained PCA model with reference data is applied to reduce
dimensionality in pseudo-bulk samples. Then, cell-type proportions in
pseudo-bulk samples are estimated using the trained model above.

``` r
df_pc_test = predict(pc_train, newdata = as.data.frame(df_test))
df_pc_test = as.data.frame(df_pc_test)
model_summary = summary(model)
  
fit_lm_model <- function(x, df_pc_test, model_summary){
  estimate = sum(model_summary$coefficients[paste0("PC", as.character(1:20)), "Estimate"]*df_pc_test[x, paste0("PC", as.character(1:20))]) + model_summary$coefficients["(Intercept)", "Estimate"]
  return(estimate)
}
estimates <- lapply(test_sample_names, fit_lm_model, df_pc_test, model_summary)              
df_pc_test$estimate = unlist(estimates)
df_pc_test$gt = test_gt[rownames(df_pc_test), ctype]
```

![](ClubCpG_deconvoluation_analysis_files/figure-gfm/gapminder-1.jpeg)<!-- -->
